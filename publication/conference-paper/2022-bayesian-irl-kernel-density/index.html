<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Diana Cai">

  
  
  
    
  
  <meta name="description" content="Inverse reinforcement learning (IRL) is a powerful framework to extract the reward function of an agent by observing its behavior, but IRL algorithms that infer point estimates can be misleading. A Bayesian approach to IRL can model a distribution over possible reward functions that could explain a set of observations, alleviating the shortcomings of learning a point estimate.  Unfortunately, existing Bayesian approaches to IRL use a $Q$-value function, estimated using $Q$-learning, in place of the likelihood function. The resulting posterior is computationally intensive to calculate, and has few theoretical guarantees. We introduce kernel density Bayesian IRL (KD-BIRL), a method that uses conditional kernel density estimation to directly approximate the likelihood used in Bayesian inference. The resulting posterior distribution contracts to the optimal reward function as the dataset sample size increases, leading to a flexible and efficient framework that extends to environments with complex state spaces. We demonstrate KD-BIRL&#39;s computational benefits and ability to represent uncertainty in the recovered reward function through a series of experiments in a Gridworld environment and on a healthcare task.">

  
  <link rel="alternate" hreflang="en-us" href="https://dicai.github.io/publication/conference-paper/2022-bayesian-irl-kernel-density/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#581845">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.42d29ab88869c832df9d4dc10c8adb6c.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-41764983-2', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://dicai.github.io/publication/conference-paper/2022-bayesian-irl-kernel-density/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@dianarycai">
  <meta property="twitter:creator" content="@dianarycai">
  
  <meta property="og:site_name" content="Diana R. Cai">
  <meta property="og:url" content="https://dicai.github.io/publication/conference-paper/2022-bayesian-irl-kernel-density/">
  <meta property="og:title" content="Kernel density Bayesian inverse reinforcement learning | Diana R. Cai">
  <meta property="og:description" content="Inverse reinforcement learning (IRL) is a powerful framework to extract the reward function of an agent by observing its behavior, but IRL algorithms that infer point estimates can be misleading. A Bayesian approach to IRL can model a distribution over possible reward functions that could explain a set of observations, alleviating the shortcomings of learning a point estimate.  Unfortunately, existing Bayesian approaches to IRL use a $Q$-value function, estimated using $Q$-learning, in place of the likelihood function. The resulting posterior is computationally intensive to calculate, and has few theoretical guarantees. We introduce kernel density Bayesian IRL (KD-BIRL), a method that uses conditional kernel density estimation to directly approximate the likelihood used in Bayesian inference. The resulting posterior distribution contracts to the optimal reward function as the dataset sample size increases, leading to a flexible and efficient framework that extends to environments with complex state spaces. We demonstrate KD-BIRL&#39;s computational benefits and ability to represent uncertainty in the recovered reward function through a series of experiments in a Gridworld environment and on a healthcare task."><meta property="og:image" content="https://dicai.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2023-01-01T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2023-01-01T00:00:00&#43;00:00">
  

  

  

  <title>Kernel density Bayesian inverse reinforcement learning | Diana R. Cai</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Diana R. Cai</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#featured">
            
            <span>Papers</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#talks">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/post/">
            
            <span>Resources</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        

        

        

      </ul>

    </div>
  </div>
</nav>

<div class="pub" itemscope itemtype="http://schema.org/CreativeWork">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Kernel density Bayesian inverse reinforcement learning</h1>

  

  
    



<meta content="2023-01-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">
<meta content="2023-01-01 00:00:00 &#43;0000 UTC" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person">Aishwarya Mandyam</span>, <span itemprop="author name" itemtype="http://schema.org/Person">Didong Li</span>, <span itemprop="author name" itemtype="http://schema.org/Person"><b>Diana Cai</b></span>, <span itemprop="author name" itemtype="http://schema.org/Person">Andrew Jones</span>, <span itemprop="author name" itemtype="http://schema.org/Person">Barbara E. Engelhardt</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>January 2023</time>
  </span>
  

  

  

  
  

  
  

  
    

  

</div>

    















<div class="btn-links mb-3">
  
  








  










  






</div>


  
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract" itemprop="text">Inverse reinforcement learning (IRL) is a powerful framework to extract the reward function of an agent by observing its behavior, but IRL algorithms that infer point estimates can be misleading. A Bayesian approach to IRL can model a distribution over possible reward functions that could explain a set of observations, alleviating the shortcomings of learning a point estimate.  Unfortunately, existing Bayesian approaches to IRL use a $Q$-value function, estimated using $Q$-learning, in place of the likelihood function. The resulting posterior is computationally intensive to calculate, and has few theoretical guarantees. We introduce kernel density Bayesian IRL (KD-BIRL), a method that uses conditional kernel density estimation to directly approximate the likelihood used in Bayesian inference. The resulting posterior distribution contracts to the optimal reward function as the dataset sample size increases, leading to a flexible and efficient framework that extends to environments with complex state spaces. We demonstrate KD-BIRL&rsquo;s computational benefits and ability to represent uncertainty in the recovered reward function through a series of experiments in a Gridworld environment and on a healthcare task.</p>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            

            
            
            <a href="/publication/#3">
              Preprint
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9">Submitted (preliminary version appeared in AABI)</div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"><p><em>A preliminary version appeared in the Symposium on Advances in Approximate
Bayesian Inference, 2022.</em></p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
</div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/bayesian-inverse-reinforcement-learning/">Bayesian inverse reinforcement learning</a>
  
</div>


    








  
  
    
  
  





  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/"></a></h5>
      
      
      
      <ul class="network-icon" aria-hidden="true">
        
      </ul>
    </div>
  </div>




  </div>
</div>



<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.39c8dc9cb91433558ef31de739736368.js"></script>

  </body>
</html>

